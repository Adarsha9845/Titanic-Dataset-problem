{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tested.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  34.5      0      0   7.8292        Q\n",
       "1         1       3  female  47.0      1      0   7.0000        S\n",
       "2         0       2    male  62.0      0      0   9.6875        Q\n",
       "3         0       3    male  27.0      0      0   8.6625        S\n",
       "4         1       3  female  22.0      1      1  12.2875        S"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:839: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  keep = (tmp_a >= first_edge)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\numpy\\lib\\histograms.py:840: RuntimeWarning: invalid value encountered in less_equal\n",
      "  keep &= (tmp_a <= last_edge)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([16., 16., 71., 97., 43., 37., 25., 17.,  9.,  1.]),\n",
       " array([ 0.17 ,  7.753, 15.336, 22.919, 30.502, 38.085, 45.668, 53.251,\n",
       "        60.834, 68.417, 76.   ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.hist(data['Survived'])\n",
    "fig, axe = plt.subplots(dpi=100)\n",
    "axe.hist(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsToBeEncoded = ['Sex', 'Embarked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labelsToBeEncoded:\n",
    "    le = LabelEncoder()\n",
    "    data[label] = le.fit_transform(data[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived     0\n",
       "Pclass       0\n",
       "Sex          0\n",
       "Age         86\n",
       "SibSp        0\n",
       "Parch        0\n",
       "Fare         1\n",
       "Embarked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].fillna(data['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0         0       3    1  34.5      0      0   7.8292         1\n",
       "1         1       3    0  47.0      1      0   7.0000         2\n",
       "2         0       2    1  62.0      0      0   9.6875         1\n",
       "3         0       3    1  27.0      0      0   8.6625         2\n",
       "4         1       3    0  22.0      1      1  12.2875         2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Survived'], axis = 1)\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical \n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import adam\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = 7))\n",
    "model.add(Dense(30, activation = 'sigmoid'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = adam(learning_rate = 1e-3), metrics = ['accuracy', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "417/417 [==============================] - 0s 802us/step - loss: 0.9031 - accuracy: 0.3645\n",
      "Epoch 2/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6625 - accuracy: 0.6067\n",
      "Epoch 3/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6450 - accuracy: 0.6283\n",
      "Epoch 4/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6417 - accuracy: 0.6283\n",
      "Epoch 5/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6347 - accuracy: 0.6259\n",
      "Epoch 6/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6316 - accuracy: 0.5923\n",
      "Epoch 7/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6300 - accuracy: 0.6355\n",
      "Epoch 8/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6301 - accuracy: 0.6451\n",
      "Epoch 9/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6289 - accuracy: 0.6331\n",
      "Epoch 10/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6288 - accuracy: 0.6331\n",
      "Epoch 11/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.6274 - accuracy: 0.6379\n",
      "Epoch 12/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6278 - accuracy: 0.6475\n",
      "Epoch 13/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.6268 - accuracy: 0.6571\n",
      "Epoch 14/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6258 - accuracy: 0.6475\n",
      "Epoch 15/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.6238 - accuracy: 0.6427\n",
      "Epoch 16/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6248 - accuracy: 0.6451\n",
      "Epoch 17/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.6203 - accuracy: 0.6475\n",
      "Epoch 18/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6185 - accuracy: 0.6547\n",
      "Epoch 19/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6168 - accuracy: 0.6547\n",
      "Epoch 20/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.6199 - accuracy: 0.6379\n",
      "Epoch 21/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6115 - accuracy: 0.6547\n",
      "Epoch 22/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.6091 - accuracy: 0.6499\n",
      "Epoch 23/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.6069 - accuracy: 0.6499\n",
      "Epoch 24/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.6043 - accuracy: 0.6571\n",
      "Epoch 25/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.6006 - accuracy: 0.6643\n",
      "Epoch 26/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.5968 - accuracy: 0.6859\n",
      "Epoch 27/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.5910 - accuracy: 0.6691\n",
      "Epoch 28/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.5911 - accuracy: 0.6811\n",
      "Epoch 29/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.5842 - accuracy: 0.6978\n",
      "Epoch 30/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5785 - accuracy: 0.7098\n",
      "Epoch 31/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5846 - accuracy: 0.6739\n",
      "Epoch 32/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.5724 - accuracy: 0.7002\n",
      "Epoch 33/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.5616 - accuracy: 0.6811\n",
      "Epoch 34/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.5519 - accuracy: 0.6906\n",
      "Epoch 35/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5444 - accuracy: 0.7098\n",
      "Epoch 36/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5379 - accuracy: 0.7218\n",
      "Epoch 37/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5383 - accuracy: 0.7194\n",
      "Epoch 38/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.5210 - accuracy: 0.6906\n",
      "Epoch 39/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.5640 - accuracy: 0.6763\n",
      "Epoch 40/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.5530 - accuracy: 0.6763\n",
      "Epoch 41/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.5382 - accuracy: 0.7050\n",
      "Epoch 42/200\n",
      "417/417 [==============================] - 0s 108us/step - loss: 0.5238 - accuracy: 0.7074\n",
      "Epoch 43/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.5099 - accuracy: 0.7146\n",
      "Epoch 44/200\n",
      "417/417 [==============================] - 0s 93us/step - loss: 0.4996 - accuracy: 0.7362\n",
      "Epoch 45/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.4851 - accuracy: 0.7602\n",
      "Epoch 46/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.4638 - accuracy: 0.7602\n",
      "Epoch 47/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.4703 - accuracy: 0.8585\n",
      "Epoch 48/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.4447 - accuracy: 0.7722\n",
      "Epoch 49/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.4270 - accuracy: 0.8010\n",
      "Epoch 50/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.4062 - accuracy: 0.8345\n",
      "Epoch 51/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.3864 - accuracy: 0.8273\n",
      "Epoch 52/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.3670 - accuracy: 0.9137\n",
      "Epoch 53/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.3412 - accuracy: 0.9760\n",
      "Epoch 54/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.3530 - accuracy: 0.9185\n",
      "Epoch 55/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.3405 - accuracy: 0.8849\n",
      "Epoch 56/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.3088 - accuracy: 0.9784\n",
      "Epoch 57/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.2983 - accuracy: 0.9664\n",
      "Epoch 58/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.2732 - accuracy: 0.9760\n",
      "Epoch 59/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.3082 - accuracy: 0.9233\n",
      "Epoch 60/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.3018 - accuracy: 0.9233\n",
      "Epoch 61/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.2734 - accuracy: 0.9592\n",
      "Epoch 62/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.2353 - accuracy: 0.9832\n",
      "Epoch 63/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.2103 - accuracy: 0.9904\n",
      "Epoch 64/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.2058 - accuracy: 0.9856\n",
      "Epoch 65/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.2312 - accuracy: 0.9568\n",
      "Epoch 66/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.2089 - accuracy: 0.9736\n",
      "Epoch 67/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1850 - accuracy: 0.9832\n",
      "Epoch 68/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.1678 - accuracy: 0.9880\n",
      "Epoch 69/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.1461 - accuracy: 0.9976\n",
      "Epoch 70/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.1337 - accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1281 - accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1519 - accuracy: 0.9784\n",
      "Epoch 73/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1177 - accuracy: 0.9952\n",
      "Epoch 74/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1098 - accuracy: 0.9976\n",
      "Epoch 75/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.1098 - accuracy: 0.9952\n",
      "Epoch 76/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.1017 - accuracy: 0.9928\n",
      "Epoch 77/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0903 - accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0826 - accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0802 - accuracy: 0.9976\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 0s 55us/step - loss: 0.0754 - accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0737 - accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0693 - accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0778 - accuracy: 0.9952\n",
      "Epoch 84/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0680 - accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.1676 - accuracy: 0.9544\n",
      "Epoch 86/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0977 - accuracy: 0.9976\n",
      "Epoch 87/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.0684 - accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0486 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0458 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0396 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0308 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0300 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0329 - accuracy: 0.9976\n",
      "Epoch 103/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0241 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0199 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0191 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0193 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "417/417 [==============================] - 0s 50us/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "417/417 [==============================] - 0s 77us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "417/417 [==============================] - 0s 112us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "417/417 [==============================] - 0s 79us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "417/417 [==============================] - 0s 86us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "417/417 [==============================] - 0s 84us/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "417/417 [==============================] - 0s 79us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 0s 57us/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "417/417 [==============================] - 0s 48us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "417/417 [==============================] - 0s 67us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "417/417 [==============================] - 0s 72us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "417/417 [==============================] - 0s 79us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "417/417 [==============================] - 0s 69us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "417/417 [==============================] - 0s 74us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "417/417 [==============================] - 0s 74us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "417/417 [==============================] - 0s 77us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "417/417 [==============================] - 0s 72us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "417/417 [==============================] - 0s 74us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "417/417 [==============================] - 0s 60us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "417/417 [==============================] - 0s 62us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "417/417 [==============================] - 0s 65us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "417/417 [==============================] - 0s 57us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "417/417 [==============================] - 0s 55us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "417/417 [==============================] - 0s 53us/step - loss: 0.0026 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a4eebb8688>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs = 200)\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 7)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.272590361445783\n",
      "201.10669538455937\n",
      "[19.120370222610276, 43.27729264706542, 33.406176851780835, 51.95560075335928, 25.6590497741547, 22.505565914043363, 23.36004408387493, 36.29608097569371, 20.954185956556728, 32.32050435885155]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from random import gauss\n",
    "\n",
    "\n",
    "\n",
    "random_numbers = [gauss(my_mean, math.sqrt(my_variance)) for i in range(10)]\n",
    "print(my_mean)\n",
    "print(my_variance)\n",
    "print(random_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.18120923562442"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(my_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.9687496529251"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(gauss(my_mean, math.sqrt(my_variance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "                   [3, 4, np.nan, 1],\n",
    "                   [np.nan, np.nan, np.nan, np.nan],\n",
    "                   [np.nan, 3, np.nan, 4]],\n",
    "                  columns=list(\"ABCD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C    D\n",
       "0  NaN  2.0 NaN  0.0\n",
       "1  3.0  4.0 NaN  1.0\n",
       "2  NaN  NaN NaN  NaN\n",
       "3  NaN  3.0 NaN  4.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20.220726698000135, 35.55839669606749, 6.048953320216452]\n"
     ]
    }
   ],
   "source": [
    "aa = [abs(gauss(my_mean, math.sqrt(my_variance))) for i in range(3)]\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['A'] == float('nan'), 'A'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A    B   C    D\n",
       "0   NaN  2.0 NaN  0.0\n",
       "1  15.0  4.0 NaN  1.0\n",
       "2   NaN  NaN NaN  NaN\n",
       "3   NaN  3.0 NaN  4.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [[0.0031915,  0.99680847],\n",
    " [0.9985292,  0.00147074],\n",
    " [0.00326472, 0.9967353 ]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = [[1.0, 0.0] if i[0] > i[1] else [0.0, 1.0] for i in aa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0], [1.0, 0.0], [0.0, 1.0]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
